{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "from imutils import face_utils\n",
    "# from pydub import AudioSegment\n",
    "# from pydub.playback import play\n",
    "import numpy as np\n",
    "import _thread\n",
    "import imutils\n",
    "import time\n",
    "import dlib\n",
    "import cv2\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    # calcular las distancias euclidianas entre los dos conjuntos de\n",
    "    # landmarks (coordenadas x, y) verticales de los ojos\n",
    "    A = distance.euclidean(eye[1], eye[5])\n",
    "    B = distance.euclidean(eye[2], eye[4])\n",
    "    # calcular la distancia euclidiana entre los landmarks\n",
    "    # horizontales de los ojos (coordenadas x, y)\n",
    "    C = distance.euclidean(eye[0], eye[3])\n",
    "    \n",
    "    # calcular la relación de aspecto del ojo\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    \n",
    "    # retornar la relación de aspecto del ojo\n",
    "    return ear\n",
    "\n",
    "hilo_flag = True  # Solo para desarrollo, en la versión final debería ser True\n",
    "l_alarma = _thread.allocate_lock()  # Puede haber N Locks, pero solo se puede adquirir uno a la vez\n",
    "\n",
    "# def sound_alarm():\n",
    "#     global ejecucion\n",
    "#     while hilo_flag:\n",
    "#         l_alarma.acquire()\n",
    "#         ALARM = AudioSegment.from_mp3(\"sound/alarm3.mp3\")\n",
    "#         for i in np.arange(3):\n",
    "#             play(ALARM)\n",
    "\n",
    "# definir dos constantes, una para la relación de aspecto del ojo para indicar\n",
    "# el parpadeo y luego una segunda constante para el número de fotogramas consecutivos\n",
    "# que el ojo debe estar por debajo del umbral para activar la alarma\n",
    "EYE_AR_THRESH = 0.22\n",
    "EYE_AR_CONSEC_FRAMES = 10\n",
    "EYE_AR_NOT_DETECTED_FRAMES = 20\n",
    "\n",
    "# inicializar los contadores de fotogramas para somnolencia y distracción de ojos\n",
    "# así como un booleano utilizado para indicar si la alarma está sonando\n",
    "COUNTER_DROWSINESS = 0\n",
    "COUNTER_EYES_NOT_DETECTED = 0\n",
    "ALARM_ON = False\n",
    "ENVIO_ALERTA = False\n",
    "MENSAJE_ALERTA = \"\"\n",
    "\n",
    "# inicializar el detector de caras de dlib (basado en HOG) y luego crear\n",
    "# el predictor de landmarks faciales\n",
    "detect = dlib.get_frontal_face_detector()\n",
    "predict = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")  # El archivo Dat es el núcleo del código\n",
    "\n",
    "# obtener los índices de los landmarks faciales para el ojo izquierdo y derecho, respectivamente\n",
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "\n",
    "# l_alarma.acquire()  # Obtener el candado antes de crear el hilo\n",
    "# _thread.start_new_thread(sound_alarm, ())  # Crea un único hilo para las alarmas\n",
    "\n",
    "def deteccionSomnolencia(frame):\n",
    "    t = time.localtime()\n",
    "    current_time = time.strftime(\"%H:%M:%S\", t)\n",
    "\n",
    "    global COUNTER_DROWSINESS \n",
    "    global COUNTER_EYES_NOT_DETECTED\n",
    "    \n",
    "    frame = imutils.resize(frame, width=450)\n",
    "    \n",
    "    # detectar caras en el fotograma en escala de grises\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    subjects = detect(gray, 0)\n",
    "    \n",
    "    # si no se detectan caras en el fotograma\n",
    "    if not subjects:\n",
    "        COUNTER_EYES_NOT_DETECTED += 1        \n",
    "        if COUNTER_EYES_NOT_DETECTED >= EYE_AR_NOT_DETECTED_FRAMES:\n",
    "            # Si está distraído\n",
    "            MENSAJE_ALERTA = \"Conductor distraído : \" + current_time \n",
    "            cv2.putText(frame, MENSAJE_ALERTA, (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            if l_alarma.locked():\n",
    "                l_alarma.release()\n",
    "    else:\n",
    "        COUNTER_EYES_NOT_DETECTED = 0\n",
    "        time.sleep(0.02)\n",
    "        if not l_alarma.locked():\n",
    "            l_alarma.acquire()\n",
    "\n",
    "        for subject in subjects:\n",
    "            # determinar los landmarks faciales para la región facial, luego\n",
    "            # convertir los landmarks faciales (coordenadas x, y) en un array NumPy\n",
    "            shape = predict(gray, subject)\n",
    "            shape = face_utils.shape_to_np(shape)  # convirtiendo a un array NumPy\n",
    "\n",
    "            # extraer las coordenadas del ojo izquierdo y derecho, luego calcular la\n",
    "            # relación de aspecto del ojo para ambos ojos\n",
    "            leftEye = shape[lStart:lEnd]           \n",
    "            rightEye = shape[rStart:rEnd]\n",
    "\n",
    "            leftEAR = eye_aspect_ratio(leftEye)\n",
    "            rightEAR = eye_aspect_ratio(rightEye)\n",
    "\n",
    "            # promediar la relación de aspecto del ojo para ambos ojos\n",
    "            ear = (leftEAR + rightEAR) / 2.0\n",
    "\n",
    "            # calcular el casco convexo para el ojo izquierdo y derecho\n",
    "            leftEyeHull = cv2.convexHull(leftEye)\n",
    "            rightEyeHull = cv2.convexHull(rightEye)\n",
    "        \n",
    "            # visualizar cada uno de los ojos\n",
    "            cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "            cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "        \n",
    "            # verificar si la relación de aspecto del ojo está por debajo del umbral de parpadeo\n",
    "            # y si es así, incrementar el contador de fotogramas de parpadeo\n",
    "            if ear < EYE_AR_THRESH:      \n",
    "                COUNTER_DROWSINESS += 1\n",
    "                # si los ojos estuvieron cerrados durante un número suficiente de fotogramas, entonces\n",
    "                # sonar la alarma\n",
    "                if COUNTER_DROWSINESS >= EYE_AR_CONSEC_FRAMES:\n",
    "                        # Si está somnoliento\n",
    "                        MENSAJE_ALERTA = \"Conductor dormido : \" + current_time  \n",
    "                        cv2.putText(frame, MENSAJE_ALERTA, (10, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                        if l_alarma.locked():\n",
    "                            l_alarma.release()\n",
    "            # de lo contrario, la relación de aspecto del ojo no está por debajo del umbral de parpadeo,\n",
    "            # por lo que se reinicia el contador y la alarma\n",
    "            else:\n",
    "                COUNTER_DROWSINESS = 0\n",
    "                time.sleep(0.02)\n",
    "                if not l_alarma.locked():\n",
    "                    l_alarma.acquire()\n",
    "                    \n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "from imutils import face_utils\n",
    "import _thread  # Agregar esta línea para importar el módulo _thread\n",
    "import numpy as np\n",
    "import imutils\n",
    "import time\n",
    "import dlib\n",
    "import cv2\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    # calcular las distancias euclidianas entre los dos conjuntos de\n",
    "    # landmarks (coordenadas x, y) verticales de los ojos\n",
    "    A = distance.euclidean(eye[1], eye[5])\n",
    "    B = distance.euclidean(eye[2], eye[4])\n",
    "    # calcular la distancia euclidiana entre los landmarks\n",
    "    # horizontales de los ojos (coordenadas x, y)\n",
    "    C = distance.euclidean(eye[0], eye[3])\n",
    "    \n",
    "    # calcular la relación de aspecto del ojo\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    \n",
    "    # retornar la relación de aspecto del ojo\n",
    "    return ear\n",
    "\n",
    "hilo_flag = True  # Solo para desarrollo, en la versión final debería ser True\n",
    "l_alarma = _thread.allocate_lock()  # Puede haber N Locks, pero solo se puede adquirir uno a la vez\n",
    "\n",
    "# definir dos constantes, una para la relación de aspecto del ojo para indicar\n",
    "# el parpadeo y luego una segunda constante para el número de fotogramas consecutivos\n",
    "# que el ojo debe estar por debajo del umbral para activar la alarma\n",
    "EYE_AR_THRESH = 0.22\n",
    "EYE_AR_CONSEC_FRAMES = 10\n",
    "EYE_AR_NOT_DETECTED_FRAMES = 20\n",
    "\n",
    "# inicializar los contadores de fotogramas para somnolencia y distracción de ojos\n",
    "# así como un booleano utilizado para indicar si la alarma está sonando\n",
    "COUNTER_DROWSINESS = 0\n",
    "COUNTER_EYES_NOT_DETECTED = 0\n",
    "ALARM_ON = False\n",
    "ENVIO_ALERTA = False\n",
    "MENSAJE_ALERTA = \"\"\n",
    "\n",
    "# inicializar el detector de caras de dlib (basado en HOG) y luego crear\n",
    "# el predictor de landmarks faciales\n",
    "detect = dlib.get_frontal_face_detector()\n",
    "predict = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")  # El archivo Dat es el núcleo del código\n",
    "\n",
    "# obtener los índices de los landmarks faciales para el ojo izquierdo y derecho, respectivamente\n",
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "\n",
    "l_alarma.acquire()  # Obtener el candado antes de crear el hilo\n",
    "#_thread.start_new_thread(sound_alarm, ())  # Crea un único hilo para las alarmas\n",
    "\n",
    "def deteccionSomnolencia(frame):\n",
    "    t = time.localtime()\n",
    "    current_time = time.strftime(\"%H:%M:%S\", t)\n",
    "\n",
    "    global COUNTER_DROWSINESS \n",
    "    global COUNTER_EYES_NOT_DETECTED\n",
    "    \n",
    "    frame = imutils.resize(frame, width=450)\n",
    "    \n",
    "    # detectar caras en el fotograma en escala de grises\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    subjects = detect(gray, 0)\n",
    "    \n",
    "    # si no se detectan caras en el fotograma\n",
    "    if not subjects:\n",
    "        COUNTER_EYES_NOT_DETECTED += 1        \n",
    "        if COUNTER_EYES_NOT_DETECTED >= EYE_AR_NOT_DETECTED_FRAMES:\n",
    "            # Si está distraído\n",
    "            MENSAJE_ALERTA = \"Conductor distraído : \" + current_time \n",
    "            cv2.putText(frame, MENSAJE_ALERTA, (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            if l_alarma.locked():\n",
    "                l_alarma.release()\n",
    "    else:\n",
    "        COUNTER_EYES_NOT_DETECTED = 0\n",
    "        time.sleep(0.02)\n",
    "        if not l_alarma.locked():\n",
    "            l_alarma.acquire()\n",
    "\n",
    "        for subject in subjects:\n",
    "            # determinar los landmarks faciales para la región facial, luego\n",
    "            # convertir los landmarks faciales (coordenadas x, y) en un array NumPy\n",
    "            shape = predict(gray, subject)\n",
    "            shape = face_utils.shape_to_np(shape)  # convirtiendo a un array NumPy\n",
    "\n",
    "            # extraer las coordenadas del ojo izquierdo y derecho, luego calcular la\n",
    "            # relación de aspecto del ojo para ambos ojos\n",
    "            leftEye = shape[lStart:lEnd]           \n",
    "            rightEye = shape[rStart:rEnd]\n",
    "\n",
    "            leftEAR = eye_aspect_ratio(leftEye)\n",
    "            rightEAR = eye_aspect_ratio(rightEye)\n",
    "\n",
    "            # promediar la relación de aspecto del ojo para ambos ojos\n",
    "            ear = (leftEAR + rightEAR) / 2.0\n",
    "\n",
    "            # calcular el casco convexo para el ojo izquierdo y derecho\n",
    "            leftEyeHull = cv2.convexHull(leftEye)\n",
    "            rightEyeHull = cv2.convexHull(rightEye)\n",
    "        \n",
    "            # visualizar cada uno de los ojos\n",
    "            cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "            cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "        \n",
    "            # verificar si la relación de aspecto del ojo está por debajo del umbral de parpadeo\n",
    "            # y si es así, incrementar el contador de fotogramas de parpadeo\n",
    "            if ear < EYE_AR_THRESH:      \n",
    "                COUNTER_DROWSINESS += 1\n",
    "                # si los ojos estuvieron cerrados durante un número suficiente de fotogramas, entonces\n",
    "                # sonar la alarma\n",
    "                if COUNTER_DROWSINESS >= EYE_AR_CONSEC_FRAMES:\n",
    "                        # Si está somnoliento\n",
    "                        MENSAJE_ALERTA = \"Conductor dormido : \" + current_time  \n",
    "                        cv2.putText(frame, MENSAJE_ALERTA, (10, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                        if l_alarma.locked():\n",
    "                            l_alarma.release()\n",
    "            # de lo contrario, la relación de aspecto del ojo no está por debajo del umbral de parpadeo,\n",
    "            # por lo que se reinicia el contador y la alarma\n",
    "            else:\n",
    "                COUNTER_DROWSINESS = 0\n",
    "                time.sleep(0.02)\n",
    "                if not l_alarma.locked():\n",
    "                    l_alarma.acquire()\n",
    "                    \n",
    "    return frame\n",
    "\n",
    "# Capturar video desde la cámara\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capturar fotograma por fotograma\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Pasar el fotograma a la función de detección de somnolencia\n",
    "    frame = deteccionSomnolencia(frame)\n",
    "\n",
    "    # Mostrar el fotograma resultante\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Detener el bucle si se presiona 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberar la captura de video y cerrar la ventana\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
